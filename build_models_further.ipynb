{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputation\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "#from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#classifers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display setting\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model data\n",
    "mdl_df = pd.read_pickle(\"./data/mdl_df_121420.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categorical features encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding category variable\n",
    "#1.set all to category\n",
    "for col in categ_columns3:\n",
    "    mdl_df.loc[:,col] = mdl_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. set to codes\n",
    "for col in categ_columns3:\n",
    "    mdl_df.loc[:, col] = mdl_df[col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. reset -1 to NaN\n",
    "for col in categ_columns3:\n",
    "    mdl_df.loc[(mdl_df[col] == -1),col] = np.nan\n",
    "    mdl_df[col] = mdl_df[col].astype('Int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numeric feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_columns1:\n",
    "    mdl_df[col] = np.log(mdl_df[col])\n",
    "    \n",
    "qtranform = QuantileTransformer(n_quantiles = int(mdl_df.shape[0]/2), output_distribution='normal').fit(mdl_df['x_num1'].to_numpy().reshape(-1, 1))\n",
    "mdl_df['x_num1'] = qtranform.transform(mdl_df['x_num1'].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple impute pipeline\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[('imputer', imputer_num)]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[('imputer', imputer_cat)]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', categorical_transformer, np.arange(13)),\n",
    "                  ('num', numeric_transformer, np.arange(13,22,1))\n",
    "                 ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_df_imputed_simple = pd.DataFrame(preprocessor.fit_transform(mdl_df.to_numpy()),columns = mdl_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iterataive imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute_estimator =  ExtraTreesRegressor(n_estimators=10, random_state=0) \n",
    "#imputer_all = IterativeImputer(random_state = 0, estimator = impute_estimator,max_iter = 20,tol = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_imputed_iter = imputer_all.fit_transform(X_train[:,range(0,3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_neighbors=10 is optimal???\n",
    "knn_impute = KNNImputer(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_df_imputed_knn = knn_impute.fit_transform((mdl_df).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#round up categircal features\n",
    "for col in categ_columns:\n",
    "    mdl_df_imputed_knn.loc[:,col] = np.round(mdl_df_imputed_knn[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U imbalanced-learn\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "from imblearn.under_sampling import AllKNN\n",
    "#from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imbalance: under resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modeldt_imb_imp(imb_method,imp_method_name,imputed_dt):\n",
    "    \"\"\" get the model train data using imbalance method and imputation method\"\"\"\n",
    "    print('imbalance resampling method: ',type(imb_method).__name__)\n",
    "    print('imputation method: ',imp_method_name)\n",
    "    return imb_method.fit_resample(imputed_dt[feature_columns].to_numpy(), imputed_dt[['y_var']].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search, build models\n",
    "def buildmodel(clsifier,param_grid,n_folds,val_metric):\n",
    "    \"\"\"build best model with sepcific classifer by gird search\n",
    "    clsifier: classifer\n",
    "    val_metric: metric to validate the best model \"\"\"\n",
    "    \n",
    "    estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', clsifier)])\n",
    "    grid_classifier = GridSearchCV(estimator, param_grid = param_grid, cv = n_folds, scoring= val_metric)\n",
    "    grid_mdls = grid_classifier.fit(X_train, y_train.ravel())\n",
    "    y_pred = grid_mdls.predict(X_test)\n",
    "    y_prob = grid_mdls.predict_proba(X_test)\n",
    "    \n",
    "    print(type(clsifier).__name__)\n",
    "    print(\"tuned hpyerparameters :(best parameters) \",grid_mdls.best_params_)\n",
    "    print(\"performance metric :\",grid_mdls.best_score_)\n",
    "    print(\"roc auc:\", metrics.roc_auc_score(y_test,y_prob[:,1]))\n",
    "    print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')\n",
    "    return grid_mdls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot features importance for tree based model\n",
    "def featr_imprt(tree_mdl,encoded_feature_names):\n",
    "    \"\"\"plot the features importance\"\"\"\n",
    "    pd.Series(tree_mdl.named_steps['classifier'].feature_importances_, encoded_feature_names)\\\n",
    "    .sort_values(ascending=True)\\\n",
    "    .plot(kind='barh', title='Feature Importances',figsize=(10, 20))\n",
    "    return pd.Series(tree_mdl.named_steps['classifier'].feature_importances_, encoded_feature_names).sort_values(ascending=False).nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[('scaler', StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[('onehot', OneHotEncoder())]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', categorical_transformer, np.arange(13)),\\\n",
    "                  ('passthrough','passthrough',np.arange(13,14)),\\\n",
    "                  ('num', numeric_transformer, np.arange(14,19,1))])\n",
    "\n",
    "#preprocessor = make_column_transformer((OneHotEncoder(), np.arange(13)),(\"passthrough\",np.arange(13,14)),(StandardScaler(), np.arange(14,19,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create model manually/single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputed dataset: mdl_df_imputed_simple,mdl_df_imputed_knn\n",
    "#resampling methods\n",
    "nm3 = NearMiss(version = 3)\n",
    "oss = OneSidedSelection(random_state=0)\n",
    "allknn = AllKNN()\n",
    "nbcr = NeighbourhoodCleaningRule()\n",
    "tl = TomekLinks\n",
    "\n",
    "imb_method = allknn\n",
    "imp_method_name = 'Simple'\n",
    "imputed_dt = mdl_df_imputed_simple\n",
    "\n",
    "X_resampled, y_resampled = get_modeldt_imb_imp(imb_method,imp_method_name,imputed_dt)\n",
    "print(\"resample classes(class, N):\",sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train /test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split model data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Logistic regression(rigid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_estimator = LogisticRegression(max_iter = 1000)\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "C_grid = dict(classifier__C = C_values)\n",
    "n_folds = 5\n",
    "val_metric = \"roc_auc\"\n",
    "\n",
    "grid_lr_mdl = buildmodel(lr_estimator,C_grid,n_folds,val_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_lr_mdl.cv_results_\n",
    "#grid_lr_mdl\n",
    "#grid_lr_mdl.best_estimator_.named_steps['classifier'].coef_.shape\n",
    "#grid_lr_mdl.best_estimator_.named_steps['preprocessor'].transformers_[0][1].get_feature_names().reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN, LightGBM, SVM, LMP using metric with macro, minor,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_X_train, m_X_test, m_y_train, m_y_test = train_test_split(mdl_df_imputed_knn_Y[feature_columns].to_numpy(), mdl_df_imputed_knn_Y[['y_var']].to_numpy(), test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(Counter(m_y_train.ravel()).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifer estimator\n",
    "knn_estimator = KNeighborsClassifier(n_neighbors = 10,weights = 'uniform')\n",
    "m_param_grid = dict(classifier__n_neighbors = [2,5,10], \n",
    "                    classifier__weights = ['uniform', 'distance'])\n",
    "\n",
    "m_n_folds = 2\n",
    "m_val_metric = \"roc_auc_ovr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', knn_estimator)])\n",
    "#no grid search\n",
    "#m_grid_knn_mdls = m_estimator.fit(m_X_train, m_y_train.ravel())\n",
    "m_grid_knn = GridSearchCV(m_estimator, param_grid = m_param_grid, cv = m_n_folds, scoring = m_val_metric)\n",
    "# with grid search\n",
    "m_grid_knn_mdls = m_grid_knn.fit(m_X_train, m_y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no grid search\n",
    "m_y_pred = m_grid_knn_mdls.predict(m_X_test)\n",
    "print('classification report:', metrics.classification_report(m_y_test, m_y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with grid search\n",
    "m_y_pred = m_grid_knn_mdls.predict(m_X_test)\n",
    "print('classification report:', metrics.classification_report(m_y_test, m_y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outcome y have 5 classes/levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_X_train, m_X_test, m_y_train, m_y_test = train_test_split(mdl_df_imputed_simple_Y[feature_columns].to_numpy(), mdl_df_imputed_simple_Y[['y_var']].to_numpy(), test_size = 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(Counter(m_y_train.ravel()).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifer estimator\n",
    "m_lgbm_estimator = LGBMClassifier(boosting_type='gbdt', num_leaves=31, learning_rate=0.1, n_estimators=100, \\\n",
    "                   subsample_for_bin=200000, objective=None,\\\n",
    "                   min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, \\\n",
    "                   subsample=1.0, subsample_freq=0, colsample_bytree=1.0, \\\n",
    "                   reg_alpha=0.0, reg_lambda=0.0, random_state=1)\n",
    "#parameters\n",
    "m_param_grid = dict(classifier__learning_rate = [0.001,0.1,1], \n",
    "                  classifier__n_estimators = [100,150],\n",
    "                  classifier__num_leaves = [10,31,100],\n",
    "                  classifier__subsample = [0.5,0.8,1],\n",
    "                  classifier__colsample_bytree = [0.5,0.8,1],\n",
    "                  classifier__min_child_weight = [0.001,1]                  \n",
    "                 )\n",
    "m_n_folds = 5\n",
    "m_val_metric = \"roc_auc_ovo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', m_lgbm_estimator)])\n",
    "m_grid_classifier = GridSearchCV(m_estimator, param_grid = m_param_grid, cv = m_n_folds, scoring= m_val_metric)\n",
    "m_grid_mdls = m_grid_classifier.fit(m_X_train, m_y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_y_pred = m_grid_mdls.predict(m_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_prob_pred = m_grid_mdls.predict_proba(m_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"roc auc:\", metrics.roc_auc_score(m_y_test.ravel(), m_prob_pred, multi_class = 'ovo',average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics.confusion_matrix(m_y_test, m_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.confusion_matrix(m_y_test, m_y_pred)\n",
    "disp = metrics.plot_confusion_matrix(m_grid_mdls, m_X_test, m_y_test)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",m_grid_mdls.best_params_)\n",
    "print(\"performance metric :\",m_grid_mdls.best_score_)\n",
    "#print(\"roc auc:\", metrics.roc_auc_score(np.argmax(m_y_test, axis = 1),m_y_pred,multi_class = 'ovo'))\n",
    "print('classification report:', metrics.classification_report(m_y_test, m_y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.classification_report(m_y_test, m_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_grid_mdls.cv_results_\n",
    "m_grid_mdls.scorer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OutputCodeClassifier strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OutputCodeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lgbm_estimator = LGBMClassifier(boosting_type='gbdt', num_leaves=100, learning_rate=0.1, n_estimators=100, \\\n",
    "                   subsample_for_bin=200000, objective=None,\\\n",
    "                   min_split_gain=0.0, min_child_samples=20, \\\n",
    "                   subsample_freq=0,\\\n",
    "                   reg_alpha=0.0, reg_lambda=0.0, random_state=1,subsample=0.5,colsample_bytree=0.5,min_child_weight = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', m_lgbm_estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lgbm_classifer = OutputCodeClassifier(m_estimator,code_size=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lgbm_mdl = output_lgbm_classifer.fit(m_X_train, m_y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_y_pred = output_lgbm_mdl.predict(m_X_test)\n",
    "#m_prob_pred = output_lgbm_mdl.predict_proba(m_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"tuned hpyerparameters :(best parameters) \",m1_grid_mdls1.best_params_)\n",
    "#print(\"performance metric :\",m1_grid_mdls1.best_score_)\n",
    "#print(\"roc auc:\", metrics.roc_auc_score(m_y_test.ravel(),m_prob_pred,multi_class = 'ovo'))\n",
    "print('classification report:', metrics.classification_report(m_y_test, m_y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END OF MULTCLASS MODELS BUILDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifer estimator\n",
    "lgbm_estimator = LGBMClassifier(boosting_type='gbdt', num_leaves=31, learning_rate=0.1, n_estimators=100, \\\n",
    "                   subsample_for_bin=200000, objective=None,\\\n",
    "                   min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, \\\n",
    "                   subsample=1.0, subsample_freq=0, colsample_bytree=1.0, \\\n",
    "                   reg_alpha=0.0, reg_lambda=0.0, random_state=1)\n",
    "#parameters\n",
    "param_grid = dict(classifier__learning_rate = [0.001,0.1,1], \n",
    "                  classifier__n_estimators = [100,150],\n",
    "                  classifier__num_leaves = [10,31,100],\n",
    "                  classifier__subsample = [0.5,0.8,1],\n",
    "                  classifier__colsample_bytree = [0.5,0.8,1],\n",
    "                  classifier__min_child_weight = [0.001,1]                  \n",
    "                 )\n",
    "n_folds = 5\n",
    "val_metric = \"roc_auc\"\n",
    "\n",
    "grid_lgbm_mdl = buildmodel(lgbm_estimator,param_grid,n_folds,val_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "#mdl_pkl_name = \"best_mdl_simple_allknn_lightgbm.pkl\"\n",
    "#with open(mdl_pkl_name, 'wb') as file:\n",
    "#    pickle.dump(grid_lgbm_mdl, file)\n",
    "# Load the Model back from file\n",
    "#with open(mdl_pkl_name, 'rb') as file:\n",
    "#    lr_mdl = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#feature importance\n",
    "top10features = featr_imprt(grid_lgbm_mdl.best_estimator_,encoded_feature_names)\n",
    "print('top 10 important features:',top10features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop searching only for logistic regression\n",
    "* loop by method of undersampling methods and imputation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbmethods = [NearMiss(version = 3),\n",
    "#              OneSidedSelection(random_state=0),\n",
    "#              AllKNN(),\n",
    "#              NeighbourhoodCleaningRule()]\n",
    "#imputednames = ['Simple','KNN']\n",
    "#imputedDFs = [mdl_df_imputed_simple,mdl_df_imputed_knn]\n",
    "\n",
    "imbmethods = [NearMiss(version = 3)]\n",
    "imputednames = ['Simple']\n",
    "imputedDFs = [mdl_df_imputed_simple]\n",
    "\n",
    "#logistic regression parameters\n",
    "lr_estimator = LogisticRegression(max_iter = 1000)\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "C_grid = dict(classifier__C = C_values)\n",
    "n_folds = 5\n",
    "val_metric = \"roc_auc\"\n",
    "grid_lr_mdl = dict()\n",
    "\n",
    "for imp_method_name,imputed_dt in zip(imputednames,imputedDFs):\n",
    "    for imb_method in imbmethods:\n",
    "        X_resampled, y_resampled = get_modeldt_imb_imp(imb_method,imp_method_name,imputed_dt)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = 0.3, random_state=0)\n",
    "        \n",
    "        grid_lr_mdl[(imp_method_name + type(imb_method).__name__)] =  buildmodel(lr_estimator,C_grid,n_folds,val_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop searching for all classifiers(split train and test datasets after resampling)\n",
    "* by imputation methods\n",
    "* by undersampling methods\n",
    "* by classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbmethods = ['None',\n",
    "              NearMiss(version = 3),\n",
    "              OneSidedSelection(random_state=0),\n",
    "              AllKNN(),\n",
    "              NeighbourhoodCleaningRule(),\n",
    "              TomekLinks()]\n",
    "imputednames = ['Simple','KNN']\n",
    "imputedDFs = [mdl_df_imputed_simple,mdl_df_imputed_knn]\n",
    "\n",
    "classifiers = [LogisticRegression(max_iter = 1000),\n",
    "              LGBMClassifier(boosting_type='gbdt', num_leaves=31, learning_rate=0.1, n_estimators=100, \\\n",
    "                   subsample_for_bin=200000, objective=None,\\\n",
    "                   min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, \\\n",
    "                   subsample=1.0, subsample_freq=0, colsample_bytree=1.0, \\\n",
    "                   reg_alpha=0.0, reg_lambda=0.0, random_state=1)]\n",
    "classifiers_paras = [dict(classifier__C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]),\n",
    "                     dict(classifier__learning_rate = [0.001,0.1,1], \n",
    "                          classifier__n_estimators = [100,150],\n",
    "                          classifier__num_leaves = [10,31,100],\n",
    "                          classifier__subsample = [0.5,0.8,1],\n",
    "                          classifier__colsample_bytree = [0.5,0.8,1],\n",
    "                          classifier__min_child_weight = [0.001,1])\n",
    "                    ]\n",
    "\n",
    "n_folds = 5\n",
    "val_metric = \"roc_auc\"\n",
    "grid_mdl = dict()\n",
    "\n",
    "for imp_method_name,imputed_dt in zip(imputednames,imputedDFs):\n",
    "    for imb_method in imbmethods:\n",
    "        if (imb_method == 'None'):\n",
    "            print(imp_method_name)\n",
    "            print('None sampling')\n",
    "            X_train, X_test, y_train, y_test = train_test_split(imputed_dt[feature_columns].to_numpy(), imputed_dt[['y_var']].to_numpy(), test_size = 0.3, random_state=0)\n",
    "        else:\n",
    "            X_resampled, y_resampled = get_modeldt_imb_imp(imb_method,imp_method_name,imputed_dt)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = 0.3, random_state=0)\n",
    "        \n",
    "        for param_grid, estimator in zip(classifiers_paras,classifiers):\n",
    "            grid_mdl[(imp_method_name + type(imb_method).__name__+ type(estimator).__name__)] =  buildmodel(estimator,param_grid,n_folds,val_metric)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop searching for all classifiers(only resampling train data)\n",
    "* by imputation methods\n",
    "* by undersampling methods\n",
    "* by classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbmethods = ['None',\n",
    "              NearMiss(version = 3),\n",
    "              OneSidedSelection(random_state=0),\n",
    "              AllKNN(),\n",
    "              NeighbourhoodCleaningRule(),\n",
    "              TomekLinks()\n",
    "             ]\n",
    "imputednames = ['Simple','KNN']\n",
    "imputedDFs = [mdl_df_imputed_simple,mdl_df_imputed_knn]\n",
    "\n",
    "classifiers = [LogisticRegression(max_iter = 1000),\n",
    "              LGBMClassifier(boosting_type='gbdt', num_leaves=31, learning_rate=0.1, n_estimators=100, \\\n",
    "                   subsample_for_bin=200000, objective=None,\\\n",
    "                   min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, \\\n",
    "                   subsample=1.0, subsample_freq=0, colsample_bytree=1.0, \\\n",
    "                   reg_alpha=0.0, reg_lambda=0.0, random_state=1)]\n",
    "classifiers_paras = [dict(classifier__C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]),\n",
    "                     dict(classifier__learning_rate = [0.001,0.1,1], \n",
    "                          classifier__n_estimators = [100,150],\n",
    "                          classifier__num_leaves = [10,31,100],\n",
    "                          classifier__subsample = [0.5,0.8,1],\n",
    "                          classifier__colsample_bytree = [0.5,0.8,1],\n",
    "                          classifier__min_child_weight = [0.001,1])\n",
    "                    ]\n",
    "\n",
    "n_folds = 5\n",
    "val_metric = \"roc_auc\"\n",
    "grid_mdl = dict()\n",
    "\n",
    "for imp_method_name,imputed_dt in zip(imputednames,imputedDFs):\n",
    "    print(imp_method_name)\n",
    "    \n",
    "    for imb_method in imbmethods:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(imputed_dt[feature_columns].to_numpy(), imputed_dt[['y_var']].to_numpy(), test_size = 0.3, random_state=0)\n",
    "        if (imb_method == 'None'):\n",
    "            print('None sampling')\n",
    "        else:\n",
    "            print(type(imb_method).__name__)\n",
    "            X_train_resampled, y_train_resampled = imb_method.fit_resample(X_train, y_train)\n",
    "            X_train = X_train_resampled\n",
    "            y_train = y_train_resampled \n",
    "        \n",
    "        for param_grid, estimator in zip(classifiers_paras,classifiers):\n",
    "            grid_mdl[(imp_method_name + type(imb_method).__name__+ type(estimator).__name__)] =  buildmodel(estimator,param_grid,n_folds,val_metric)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imbalance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_space(X, y, label='Classes'):   \n",
    "    colors = ['#1F77B4', '#FF7F0E']\n",
    "    markers = ['o', 's']\n",
    "    for l, c, m in zip(np.unique(y), colors, markers):\n",
    "        plt.scatter(\n",
    "            X[y==l, 0],\n",
    "            X[y==l, 1],\n",
    "            c=c, label=l, marker=m\n",
    "        )\n",
    "    plt.title(label)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2way to show all model data(population)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(mdl_df_imputed_simple[feature_columns].to_numpy())\n",
    "y = mdl_df_imputed_simple[['y_var']].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_space(X, y, 'Imbalanced dataset (2 PCA components)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks()\n",
    "X_tl, y_tl = tl.fit_sample(X, y)\n",
    "\n",
    "#print('Removed indexes:', id_tl)\n",
    "print('sampling size%:',X_tl.shape[0], 100 * X_tl.shape[0]/X.shape[0])\n",
    "\n",
    "plot_2d_space(X_tl, y_tl, 'Tomek links under-sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import AllKNN\n",
    "ak = AllKNN()\n",
    "X_ak, y_ak = ak.fit_sample(X, y)\n",
    "print('sampling size: %d, percentage: %d', X_ak.shape[0],100* X_ak.shape[0]/X.shape[0])\n",
    "plot_2d_space(X_ak, y_ak, 'ALLKNN under-sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare feature distributions between populatin and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ak,y_ak = ak.fit_sample(mdl_df_imputed_simple[feature_columns].to_numpy(), mdl_df_imputed_simple[['y_var']].to_numpy().ravel())\n",
    "Xy_ak_df = pd.concat([pd.DataFrame(data = X_ak, columns = (feature_columns)), pd.DataFrame(data = y_ak, columns = (['y_var']))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one way summary frequency table\n",
    "dt = mdl_df_imputed_simple\n",
    "for col in categ_columns3:\n",
    "    print(col)\n",
    "    #mdl_df[col].value_counts(dropna = False)\n",
    "    pd.concat([dt[col].value_counts(dropna = False),100 * dt[col].value_counts(dropna = False, normalize = True)],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram for numeric features\n",
    "dt = mdl_df_imputed_simple\n",
    "fig, axs = plt.subplots(len(num_columns), 1, sharey=False, tight_layout=False,figsize=(10, 20))\n",
    "i = 0\n",
    "for col in num_columns:\n",
    "    axs[i].hist(dt[col],100)\n",
    "    i = i+1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
