{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model data\n",
    "mdl_df = pd.read_pickle(\"./data/mdl_df_121420.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##modeling\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "#from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_df_reduced = (mdl_df.loc[:,feature_columns + ['y_var']])\n",
    "mdl_df_imputed_simple = pd.DataFrame(preprocessor.fit_transform(mdl_df_reduced.to_numpy()),columns = mdl_df_reduced.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U imbalanced-learn\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "from imblearn.under_sampling import AllKNN\n",
    "#from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#classifers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modeldt_imb_imp(imb_method,imp_method_name,imputed_dt):\n",
    "    \"\"\" get the model train data using imbalance method and imputation method\"\"\"\n",
    "    print('imbalance resampling method: ',type(imb_method).__name__)\n",
    "    print('imputation method: ',imp_method_name)\n",
    "    return imb_method.fit_resample(imputed_dt[feature_columns].to_numpy(), imputed_dt[['y_var']].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search, build models\n",
    "def buildmodel(clsifier,param_grid,n_folds,val_metric):\n",
    "    \"\"\"build best model with sepcific classifer by gird search\n",
    "    clsifier: classifer\n",
    "    val_metric: metric to validate the best model \"\"\"\n",
    "    \n",
    "    estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', clsifier)])\n",
    "    grid_classifier = GridSearchCV(estimator, param_grid = param_grid, cv = n_folds, scoring= val_metric)\n",
    "    grid_mdls = grid_classifier.fit(X_train, y_train.ravel())\n",
    "    y_pred = grid_mdls.predict(X_test)\n",
    "    y_prob = grid_mdls.predict_proba(X_test)\n",
    "    \n",
    "    print(type(clsifier).__name__)\n",
    "    print(\"tuned hpyerparameters :(best parameters) \",grid_mdls.best_params_)\n",
    "    print(\"performance metric :\",grid_mdls.best_score_)\n",
    "    print(\"roc auc:\", metrics.roc_auc_score(y_test,y_prob[:,1]))\n",
    "    print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')\n",
    "    return grid_mdls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot features importance for tree based model\n",
    "def featr_imprt(tree_mdl,encoded_feature_names):\n",
    "    \"\"\"plot the features importance\"\"\"\n",
    "    pd.Series(tree_mdl.named_steps['classifier'].feature_importances_, encoded_feature_names)\\\n",
    "    .sort_values(ascending=True)\\\n",
    "    .plot(kind='barh', title='Feature Importances',figsize=(10, 20))\n",
    "    return pd.Series(tree_mdl.named_steps['classifier'].feature_importances_, encoded_feature_names).sort_values(ascending=False).nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary outcome models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer((\"passthrough\",np.arange(0,14)),(StandardScaler(),np.arange(14,19,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mdl_df_imputed_simple[feature_columns].to_numpy(), mdl_df_imputed_simple[['y_var']].to_numpy(), test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#classifer estimator\n",
    "lgbm_estimator = LGBMClassifier(boosting_type='gbdt', num_leaves=31, learning_rate=0.1, n_estimators=100, \\\n",
    "                   subsample_for_bin=200000, objective=None,\\\n",
    "                   min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, \\\n",
    "                   subsample=1.0, subsample_freq=5, colsample_bytree=1.0, \\\n",
    "                   reg_alpha=0.0, reg_lambda=0.0, random_state=1)\n",
    "#parameters\n",
    "param_grid = dict(\n",
    "#    classifier__boosting_type = ['dart','gbdt'],\n",
    "    classifier__learning_rate = [0.001,0.1,1], \n",
    "    classifier__n_estimators = [50,150,200],\n",
    "    classifier__num_leaves = [10,31,100,150],\n",
    "#   classifier__max_depth = [5,7,10],\n",
    "    classifier__min_child_samples = [10,20,50,100],\n",
    "#   classifier__min_child_weight = [0.001,0.1,1,10],\n",
    "    classifier__subsample = [0.5,0.8,1],\n",
    "    classifier__colsample_bytree = [0.5,0.8,1]\n",
    ")\n",
    "# the parameters of the best models obtain from the above param_grid search\n",
    "param_grid = dict(\n",
    "#    classifier__boosting_type = ['dart','gbdt'],\n",
    "    classifier__learning_rate = [0.1], \n",
    "    classifier__n_estimators = [150],\n",
    "    classifier__num_leaves = [100],\n",
    "#   classifier__max_depth = [5,7,10],\n",
    "#    classifier__min_child_samples = [10,20,50,100],\n",
    "#   classifier__min_child_weight = [0.001,0.1,1,10],\n",
    "    classifier__subsample = [0.5],\n",
    "    classifier__colsample_bytree = [0.5],\n",
    "#    classifier__early_stopping_rounds = [10],\n",
    "    classifier__categorical_feature = np.arange(0,13)\n",
    ")\n",
    "\n",
    "n_folds = 5\n",
    "val_metric = \"roc_auc\"\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', lgbm_estimator)])\n",
    "grid_classifier = GridSearchCV(estimator, param_grid = param_grid, cv = n_folds, scoring= val_metric)\n",
    "grid_mdls = grid_classifier.fit(X_train, y_train.ravel())\n",
    "\n",
    "grid_lgbm_mdl = buildmodel(lgbm_estimator,param_grid,n_folds,val_metric)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best model: NONE resampling, LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalance resampling, models overfitting\n",
    "#akn = AllKNN()\n",
    "#ncr = NeighbourhoodCleaningRule()\n",
    "#X_train_resampled, y_train_resampled = akn.fit_resample(X_train, y_train)\n",
    "#X_train = X_train_resampled\n",
    "#y_train = y_train_resampled \n",
    "\n",
    "lgbm_classifier = LGBMClassifier(boosting_type='gbdt', num_leaves=100, learning_rate=0.1, n_estimators=150, \\\n",
    "                   subsample_for_bin=200000, objective=None,\\\n",
    "                   min_split_gain=0.0, min_child_weight=1, min_child_samples=20, \\\n",
    "                   subsample=0.5, subsample_freq=0, colsample_bytree=0.5, \\\n",
    "                   reg_alpha=0.0, reg_lambda=0.0, random_state=1)\n",
    "\n",
    "lgbm_estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', lgbm_classifier)])\n",
    "lgbm_mdl = lgbm_estimator.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm_mdl.predict(X_test)\n",
    "y_prob = lgbm_mdl.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train accuracy:\", metrics.accuracy_score(y_train,lgbm_mdl.predict(X_train)))\n",
    "print(\"test accuracy:\", metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"roc auc:\", metrics.roc_auc_score(y_test,y_prob[:,1]))\n",
    "print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-plot\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_precision_recall(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test,y_pred,normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_train,lgbm_mdl.predict(X_train),normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_roc(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_roc(y_train, lgbm_mdl.predict_proba(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cumulative gain curve and lift chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_cumulative_gain(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skplt.metrics.plot_lift_curve(y_test, y_prob)\n",
    "#figsize=(12, 8), title_fontsize=20, text_fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explain model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display dataset\n",
    "#categorical features\n",
    "display_dt = mdl_df_imputed_simple[feature_columns].copy()\n",
    "for col in categ_columns3:\n",
    "    lb = preprocessing.LabelEncoder()\n",
    "    lb_e = lb.fit(mdl_df_display[~pd.isnull(mdl_df_display[col])][col])\n",
    "    ts = (display_dt[col].astype('Int8').to_list())\n",
    "    display_dt[col] = lb_e.inverse_transform(ts)  \n",
    "\n",
    "#inverse back to original values of numeric features  \n",
    "# log(), exp()\n",
    "for col in ['num_var1']:\n",
    "    display_dt[col] = np.exp(display_dt[col])\n",
    "\n",
    "#QuantileTransformer inverse\n",
    "display_dt['num_var2'] = pwtranf.inverse_transform(display_dt['num_var2'].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mdl = lgbm_mdl.named_steps['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data = Pipeline(steps=[('preprocessor', preprocessor)]).fit_transform(mdl_df_imputed_simple[feature_columns]), columns = feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(best_mdl)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary plot, feature importance\n",
    "shap.summary_plot(shap_values[1], X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the JS visualization code to the notebook\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data instance explaination for prediction contribution\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][100,:], display_dt.iloc[100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependence plots\n",
    "#for name in feature_columns:\n",
    "#    shap.dependence_plot(name, shap_values[1], X, display_features = display_dt)\n",
    "for name in feature_columns:\n",
    "    shap.dependence_plot(name, shap_values[1], display_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interaction effect\n",
    "shap.dependence_plot('X1', shap_values[1], X, display_features = display_dt,interaction_index = 'X2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi class(5) classification--lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_X_train, m_X_test, m_y_train, m_y_test = train_test_split(mdl_df_imputed_simple_y[feature_columns].to_numpy(), mdl_df_imputed_simple_y[['y_var']].to_numpy(), test_size = 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(Counter(m_y_train.ravel()).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifer estimator\n",
    "m_lgbm_estimator = LGBMClassifier(boosting_type='gbdt', num_leaves=31, learning_rate=0.1, n_estimators=100, \\\n",
    "                   subsample_for_bin=200000, objective=None,\\\n",
    "                   min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, \\\n",
    "                   subsample=1.0, subsample_freq=0, colsample_bytree=1.0, \\\n",
    "                   reg_alpha=0.0, reg_lambda=0.0, random_state=1)\n",
    "#parameters\n",
    "m_param_grid = dict(classifier__learning_rate = [0.001,0.1,1], \n",
    "                  classifier__n_estimators = [100,150],\n",
    "                  classifier__num_leaves = [10,31,100],\n",
    "                  classifier__subsample = [0.5,0.8,1],\n",
    "                  classifier__colsample_bytree = [0.5,0.8,1],\n",
    "                  classifier__min_child_weight = [0.001,1]                  \n",
    "                 )\n",
    "m_n_folds = 5\n",
    "m_val_metric = \"roc_auc_ovo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', m_lgbm_estimator)])\n",
    "m_grid_classifier = GridSearchCV(m_estimator, param_grid = m_param_grid, cv = m_n_folds, scoring= m_val_metric)\n",
    "m_grid_mdls = m_grid_classifier.fit(m_X_train, m_y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_y_pred = m_grid_mdls.predict(m_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_prob_pred = m_grid_mdls.predict_proba(m_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"roc auc:\", metrics.roc_auc_score(m_y_test.ravel(), m_prob_pred, multi_class = 'ovo',average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics.confusion_matrix(m_y_test, m_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.confusion_matrix(m_y_test, m_y_pred)\n",
    "disp = metrics.plot_confusion_matrix(m_grid_mdls, m_X_test, m_y_test)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",m_grid_mdls.best_params_)\n",
    "print(\"performance metric :\",m_grid_mdls.best_score_)\n",
    "#print(\"roc auc:\", metrics.roc_auc_score(np.argmax(m_y_test, axis = 1),m_y_pred,multi_class = 'ovo'))\n",
    "print('classification report:', metrics.classification_report(m_y_test, m_y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_grid_mdls.cv_results_\n",
    "m_grid_mdls.scorer_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
