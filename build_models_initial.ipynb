{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample codes: Grid searching for various classifers by model pipeline\n",
    "* KNN\n",
    "* SVM\n",
    "* Neural Network\n",
    "* Logistic Regression\n",
    "* Tree-based: XGboost, LightGBM, Random Forest, GBM, Ada Boost, Stacking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputation\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer\n",
    "#from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display setting\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model data\n",
    "mdl_df = pd.read_pickle(\"./data/mdl_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing data report for each feature\n",
    "df = mdl_df\n",
    "for crossvar in feature_columns:\n",
    "    #count number of rows with missing values\n",
    "    n_miss = df[[crossvar]].isnull().sum()\n",
    "    perc = n_miss / df.shape[0] * 100\n",
    "    print('> %s, Missing: %d (%.1f%%)' % (crossvar, n_miss, perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one way summary frequency table\n",
    "dt = mdl_df\n",
    "for col in categ_columns3:\n",
    "    print(col)\n",
    "    pd.concat([dt[col].value_counts(dropna = False),100 * dt[col].value_counts(dropna = False, normalize = True)],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding category variables\n",
    "#1.set all to category\n",
    "for col in categ_columns3:\n",
    "    mdl_df.loc[:,col] = mdl_df[col].astype('category')\n",
    "#2. set to codes\n",
    "for col in categ_columns3:\n",
    "    mdl_df.loc[:, col] = mdl_df[col].cat.codes\n",
    "#3 reset -1 to NaN\n",
    "for col in categ_columns3:\n",
    "    mdl_df.loc[(mdl_df[col] == -1),col] = np.nan\n",
    "    mdl_df[col] = mdl_df[col].astype('Int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical features name_code: \n",
    "#encode_cat_cols = []\n",
    "#for col in categ_columns3:\n",
    "#    encode_cat_cols = encode_cat_cols + (col + '_' + mdl_df[col].cat.categories.astype('str').values).tolist()\n",
    "#encode_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranformation for numeric variables\n",
    "for col in num_colmuns:\n",
    "    mdl_df[col] = np.log(mdl_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation\n",
    "mdl_df[num_columns].corr()\n",
    "mdl_df[feature_columns].corr()\n",
    "\n",
    "#pairwise features plot\n",
    "sns.pairplot(mdl_df, kind='reg', diag_kind='kde')\n",
    "sns.pairplot(mdl_df,hue=\"loanclose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mdl_df[feature_columns].to_numpy(), mdl_df[['y_var']].to_numpy(), test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline\n",
    "#imputer_num = IterativeImputer(random_state = 0, estimator = impute_estimator,max_iter = 50,tol = 0.001))\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[('imputer', imputer_num),\n",
    "           ('scaler', StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[('imputer', imputer_cat),\n",
    "           ('onehot', OneHotEncoder())]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', categorical_transformer, np.arange(13)),\n",
    "                  ('num', numeric_transformer, np.arange(13,19,1))\n",
    "                 ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## grid search logistic regression(rigid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_estimator = LogisticRegression(max_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', lr_estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "C_grid = dict(classifier__C = C_values)\n",
    "\n",
    "# Set the amount of folds for the cross-validation\n",
    "n_folds = 5\n",
    "\n",
    "# Do a model fit over a grid of C hyperparameters\n",
    "grid_logReg = GridSearchCV(estimator, param_grid = C_grid, cv = n_folds, scoring= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_lr_mdl = grid_logReg.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",grid_lr_mdl.best_params_)\n",
    "print(\"accuracy :\",grid_lr_mdl.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lr_mdl.best_estimator_.named_steps['classifier'].coef_.transpose().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_lr_mdl.predict(X_test)\n",
    "#y_score = grid_lr_mdl.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test,y_pred)\n",
    "metrics.f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_svc = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                      ('classifier', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = np.logspace(-1, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_range = np.logspace(-2, -2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "param_grid = dict(classifier__gamma = gamma_range, classifier__C = C_range)\n",
    "grid_svc = GridSearchCV(estimator_svc, param_grid = param_grid, cv = n_folds, scoring= 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svc_mdl = grid_svc.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",grid_svc_mdl.best_params_)\n",
    "print(\"roc_auc :\",grid_svc_mdl.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_svc_mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test,y_pred)\n",
    "metrics.f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_linsvc = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                      ('classifier', LinearSVC(max_iter = 5000,C = 0.1,tol = 1e-3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linsvc_mdl = estimator_linsvc.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linsvc_mdl.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linsvc_mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test,y_pred)\n",
    "metrics.roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grid search Tree based models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, min_samples_split=2, min_samples_leaf=1, max_depth=3, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False)\n",
    "gbc_estimator = GradientBoostingClassifier(max_depth = 5, subsample=0.8, random_state=1)\n",
    "estimator_gbc = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                      ('classifier', gbc_estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "param_grid = dict(classifier__learning_rate = [0.01,0.1], \n",
    "                  classifier__n_estimators = [50,100,150],\n",
    "                  classifier__subsample = [0.5,0.8,1],\n",
    "                  classifier__max_depth= [3,5,8],\n",
    "                  classifier__max_features = [5,7,9,11,13,15,17,19]\n",
    "                 )\n",
    "grid_gbc = GridSearchCV(estimator_gbc, param_grid = param_grid, cv = n_folds, scoring= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gbc_mdl = grid_gbc.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",grid_gbc_mdl.best_params_)\n",
    "print(\"accuracy :\",grid_gbc_mdl.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_gbc_mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test,y_pred)\n",
    "print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "#mdl_pkl_name = \"mdl_gbc_smplimpt_noapr.pkl\"\n",
    "#with open(mdl_pkl_name, 'wb') as file:\n",
    "#    pickle.dump(grid_gbc_mdl, file)\n",
    "# Load the Model back from file\n",
    "#with open(mdl_pkl_name, 'rb') as file:\n",
    "#    lr_mdl = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_feature_names = np.concatenate([encode_cat_cols, num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##feature importance\n",
    "pd.Series(grid_gbc_mdl.best_estimator_.named_steps['classifier'].feature_importances_, encoded_feature_names)\\\n",
    ".sort_values(ascending=False).nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(grid_gbc_mdl.best_estimator_.named_steps['classifier'].feature_importances_,encoded_feature_names)\\\n",
    ".sort_values(ascending=True)\\\n",
    ".plot(kind='barh', title='Feature Importances',figsize=(10, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "rf_estimator = RandomForestClassifier()\n",
    "estimator_rf = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                      ('classifier', rf_estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "param_grid = dict(classifier__criterion = ['gini', 'entropy'], \n",
    "                  classifier__n_estimators = [50,100,150],\n",
    "                  classifier__max_samples = [0.5,0.8,1],\n",
    "                  classifier__max_depth = [3,5,8,None],\n",
    "                  classifier__max_features = ['auto', 'sqrt', 'log2']\n",
    "                 )\n",
    "grid_rf = GridSearchCV(estimator_rf, param_grid = param_grid, cv = n_folds, scoring= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf_mdl = grid_rf.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",grid_rf_mdl.best_params_)\n",
    "print(\"accuracy :\",grid_rf_mdl.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_rf_mdl.predict(X_test)\n",
    "#grid_rf_mdl.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test,y_pred)\n",
    "print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(grid_rf_mdl.best_estimator_.named_steps['classifier'].feature_importances_,encoded_feature_names)\\\n",
    ".sort_values(ascending=True)\\\n",
    ".plot(kind='barh', title='Feature Importances',figsize=(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "#mdl_pkl_name = \"mdl_rf_smplimpt_noapr.pkl\"\n",
    "#with open(mdl_pkl_name, 'wb') as file:\n",
    "#    pickle.dump(grid_rf_mdl, file)\n",
    "# Load the Model back from file\n",
    "#with open(mdl_pkl_name, 'rb') as file:\n",
    "#    lr_mdl = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoostClassifier(base_estimator=None, *, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)\n",
    "ada_estimator = AdaBoostClassifier()\n",
    "estimator_ada = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                      ('classifier', ada_estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "param_grid = dict(classifier__learning_rate = [0.1,1],\n",
    "                  classifier__n_estimators = [50,100]\n",
    "                 )\n",
    "grid_ada = GridSearchCV(estimator_ada, param_grid = param_grid, cv = n_folds, scoring= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ada_mdl = grid_ada.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",grid_ada_mdl.best_params_)\n",
    "print(\"accuracy :\",grid_ada_mdl.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_ada_mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test,y_pred)\n",
    "print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "#mdl_pkl_name = \"mdl_adaboost_smplimpt_noapr.pkl\"\n",
    "#with open(mdl_pkl_name, 'wb') as file:\n",
    "#    pickle.dump(grid_ada_mdl, file)\n",
    "# Load the Model back from file\n",
    "#with open(mdl_pkl_name, 'rb') as file:\n",
    "#    lr_mdl = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_dst = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                      ('classifier', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstree_mdl = estimator_dst.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstree_mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree.plot_tree(dstree_mdl.named_steps['classifier'], filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_estimator = MLPClassifier(hidden_layer_sizes=(40,),solver = 'adam', activation='relu', alpha=0.0001, max_iter = 1000,learning_rate='constant', learning_rate_init=0.001, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_mlp = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                      ('classifier', mlp_estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "param_grid = dict(classifier__hidden_layer_sizes = [(40, 30), (40,20,10)], \n",
    "                  classifier__alpha = [0.00001,0.0001,0.1],\n",
    "                  classifier__learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "                 )\n",
    "grid_mlp = GridSearchCV(estimator_mlp, param_grid = param_grid, cv = n_folds, scoring= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_mlp_mdl = grid_mlp.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",grid_mlp_mdl.best_params_)\n",
    "print(\"accuracy :\",grid_mlp_mdl.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_mlp_mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test,y_pred)\n",
    "print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "#mdl_pkl_name = \"mdl_MLP_smplimpt_noapr.pkl\"\n",
    "#with open(mdl_pkl_name, 'wb') as file:\n",
    "#    pickle.dump(grid_mlp_mdl, file)\n",
    "# Load the Model back from file\n",
    "#with open(mdl_pkl_name, 'rb') as file:\n",
    "#    lr_mdl = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install python packages\n",
    "#!pip install xgboost\n",
    "#!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Disbursed'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Disbursed'].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Disbursed'], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator = XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "              min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "              objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_xgb = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                      ('classifier', xgb_estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "param_grid = dict(classifier__learning_rate = [0.001,0.1,1], \n",
    "                  classifier__n_estimators = [100,150],\n",
    "                  classifier__max_depth = [10,15],\n",
    "                  classifier__subsample = [0.5,0.8,1],\n",
    "                  classifier__colsample_bytree = [0.5,0.8],\n",
    "                  classifier__gamma = [0,0.1],\n",
    "                  classifier__min_child_weight = [1,5]                  \n",
    "                 )\n",
    "grid_xgb = GridSearchCV(estimator_xgb, param_grid = param_grid, cv = n_folds, scoring= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_xgb_mdl = grid_xgb.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_xgb_mdl.best_params_, grid_xgb_mdl.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#({'classifier__learning_rate': 0.1,\n",
    "#  'classifier__max_depth': 10,\n",
    "#  'classifier__n_estimators': 150},\n",
    "# 0.7918127123210275)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_xgb_mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.5165817910818531\n",
    "metrics.f1_score(y_test,y_pred)\n",
    "print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "#mdl_pkl_name = \"mdl_xgb_smplimpt_noapr.pkl\"\n",
    "#with open(mdl_pkl_name, 'wb') as file:\n",
    "#    pickle.dump(grid_xgb_mdl, file)\n",
    "# Load the Model back from file\n",
    "#with open(mdl_pkl_name, 'rb') as file:\n",
    "#    lr_mdl = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance\n",
    "pd.Series(grid_xgb_mdl.best_estimator_.named_steps['classifier'].feature_importances_, encoded_feature_names)\\\n",
    ".sort_values(ascending=False).nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance\n",
    "pd.Series(grid_xgb_mdl.best_estimator_.named_steps['classifier'].feature_importances_, encoded_feature_names)\\\n",
    ".sort_values(ascending=True)\\\n",
    ".plot(kind='barh', title='Feature Importances',figsize=(10, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs\n",
    "knn_estimator = KNeighborsClassifier()\n",
    "estimator_knn = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                      ('classifier', knn_estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "param_grid = dict(classifier__n_neighbors = [2,5,10], classifier__weights = ['uniform', 'distance'])\n",
    "grid_knn = GridSearchCV(estimator_knn, param_grid = param_grid, cv = n_folds, scoring= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_knn_mdl = grid_knn.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",grid_knn_mdl.best_params_)\n",
    "print(\"accuracy :\",grid_knn_mdl.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_knn_mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score with best estimators is 0.43737882900348973\n",
    "metrics.f1_score(y_test,y_pred)\n",
    "print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "#mdl_pkl_name = \"mdl_knn_smplimpt_noapr.pkl\"\n",
    "#with open(mdl_pkl_name, 'wb') as file:\n",
    "#    pickle.dump(grid_knn_mdl, file)\n",
    "# Load the Model back from file\n",
    "#with open(mdl_pkl_name, 'rb') as file:\n",
    "#    lr_mdl = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from lightgbm.sklearn import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_estimator = LGBMClassifier(boosting_type='gbdt', num_leaves=31, learning_rate=0.1, n_estimators=100, \\\n",
    "                   subsample_for_bin=200000, objective=None,\\\n",
    "                   min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, \\\n",
    "                   subsample=1.0, subsample_freq=0, colsample_bytree=1.0, \\\n",
    "                   reg_alpha=0.0, reg_lambda=0.0, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_lgbm = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                      ('classifier', lgbm_estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_folds = 5\n",
    "scv = StratifiedKFold(n_splits=5)\n",
    "param_grid = dict(classifier__learning_rate = [0.001,0.1,1], \n",
    "                  classifier__n_estimators = [100,150],\n",
    "                  classifier__num_leaves = [10,31,100],\n",
    "                  classifier__subsample = [0.5,0.8,1],\n",
    "                  classifier__colsample_bytree = [0.5,0.8,1],\n",
    "                  classifier__min_child_weight = [0.001,1]                  \n",
    "                 )\n",
    "grid_lgbm = GridSearchCV(estimator_lgbm, param_grid = param_grid, cv = scv, scoring= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lgbm_mdl = grid_lgbm.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lgbm.best_params_, grid_lgbm.best_score_\n",
    "#({'classifier__colsample_bytree': 0.5,\n",
    "#  'classifier__learning_rate': 0.1,\n",
    "##  'classifier__min_child_weight': 0.001,\n",
    "#  'classifier__n_estimators': 150,\n",
    "#  'classifier__num_leaves': 31,\n",
    "#  'classifier__subsample': 0.5},\n",
    "# 0.7947761770351673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test,y_pred)\n",
    "print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "#mdl_pkl_name = \"mdl_lgbm_smplimpt_noapr.pkl\"\n",
    "#with open(mdl_pkl_name, 'wb') as file:\n",
    "#    pickle.dump(grid_lgbm_mdl, file)\n",
    "# Load the Model back from file\n",
    "#with open(mdl_pkl_name, 'rb') as file:\n",
    "#    lr_mdl = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance\n",
    "pd.Series(grid_lgbm_mdl.best_estimator_.named_steps['classifier'].feature_importances_, encoded_feature_names)\\\n",
    ".sort_values(ascending=True)\\\n",
    ".plot(kind='barh', title='Feature Importances',figsize=(10, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('knn',make_pipeline(preprocessor,KNeighborsClassifier(n_neighbors=10,weights='uniform'))),\n",
    "    ('nn', make_pipeline(preprocessor,MLPClassifier(hidden_layer_sizes=(40,30),solver = 'adam', activation='relu', alpha=0.1, max_iter = 1000,learning_rate='constant', learning_rate_init=0.001, random_state=1))),\n",
    "    ('xgb',make_pipeline(preprocessor,XGBClassifier(learning_rate =0.1, n_estimators=100, max_depth=10,\\\n",
    "              min_child_weight=5, gamma=0.1, subsample=1, colsample_bytree=0.8,\\\n",
    "              objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27))),\n",
    "    ('rf', make_pipeline(preprocessor,RandomForestClassifier(n_estimators=150, random_state=42,max_samples=0.5))),\n",
    "    ('gbm', make_pipeline(preprocessor,GradientBoostingClassifier(max_depth = 8, subsample=1, random_state=1,learning_rate=0.1, max_features=9, n_estimators=150))),\n",
    "    ('lgbm',make_pipeline(preprocessor,LGBMClassifier(colsample_bytree=0.5,learning_rate=0.1,min_child_weight=0.001,n_estimators=150,num_leaves=31,subsample=0.5)))\n",
    "]\n",
    "\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(C=0.1, max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stack_mdl = clf.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "#mdl_pkl_name = \"mdl_stack_smplimpt_noapr.pkl\"\n",
    "#with open(mdl_pkl_name, 'wb') as file:\n",
    "#    pickle.dump(stack_mdl, file)\n",
    "# Load the Model back from file\n",
    "#with open(mdl_pkl_name, 'rb') as file:\n",
    "#    lr_mdl = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_mdl.score(X_test, y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = stack_mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test,y_pred)\n",
    "metrics.f1_score(y_test,y_pred)\n",
    "print('classification report:', metrics.classification_report(y_test, y_pred), sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
